---
featured: true
title: 解決 Node.js 單執行緒效能瓶頸的幾種實戰解法
date: 2025-12-30 01:01:01 +0800
thumbnail: nodejs-worker-threads.jpg
category: Fontend
tags: ['Uptime Kuma', 'Node.js', 'Bun', 'Worker Threads', 'Cluster', 'Performance', 'Monitoring']
description: 在擴充 Uptime Kuma 負載平衡與 Failover 功能時，踩到 Node.js 單執行緒瓶頸，透過 Worker Threads、Cluster 與 Bun 把多核心效能真正吃滿。
author: Mark Ku
slug: 2025/12/30/nodejs-worker-threads-bun-performance
---

## 前言

在幫 **Uptime Kuma** 擴充負載平衡（Load Balancing）與節點切換（Failover）功能的過程中，我意外踩到了一個Node.Js的效能瓶頸：

同一套程式，在家裡的機器可以穩穩跑 **1000 個監控**，但是放到一台 **13 年前的測試機** 上時，大概 **單一節點跑到 800 個監控就開始頓、反應變慢**。

這也逼得我回頭重新檢查，底是我寫壞，還是 Node.js 天生的限制？

---

## 為什麼 800 個監控就開始頓？

Uptime Kuma 本身就是一個高頻輪詢（polling）的系統：每個監控 item 都要定期發出請求、判斷成功或失敗、更新狀態，現在又多了一層：

在新一點的 CPU 上，這些重計算還撐得住；但在那台 13 年前的測試機上，**大約 800 個監控** 時，以下現象開始出現：

- 後台 UI 操作有明顯「卡一下」的感覺
- 定時任務排程延遲，比原本設定的時間晚觸發
- 整體 CPU 使用率接近單核心吃滿，但其他核心卻閒著

這個「一顆核心滿載、其他核心在發呆」的畫面，直接指向一件事：**Node.js 的單執行緒模型，已經成為瓶頸。**

---
很多人聽到「Node.js 是單執行緒」時，直覺會以為它一次只能用到一顆 CPU。其實比較正確的說法是：

- 跑 JavaScript 的主執行緒（event loop）只有一條
- 當 Node.js 要做讀寫檔案、連線網路、查 DNS 這種 I/O 工作時，底層的 libuv 會偷偷開好幾條背景小線（thread pool），幫你同時處理很多 I/O，主線上的 JavaScript 就不用一個一個傻傻等，可以先去忙別的事。

問題出在：**但當監控數量很多、輪詢頻率又很高時**，就會出現一堆「需要重複計算」的邏輯一起擠在同一條 event loop 上。這些計算又不是在等 I/O，而是實打實吃 CPU，久了自然就變成效能瓶頸。

> JavaScript 本身是單執行緒，只能一條一條依序在 call stack 裡跑程式碼，如果在裡面做很久的同步工作（例如死迴圈），主執行緒就會被 block 住。
遇到像 setTimeout、HTTP 請求這種「慢動作」，執行環境會先把它們丟給底層 API 去做，等完成後再把 callback 放進 queue，由 event loop 在 call stack 空閒時，一個一個把 callback 拉回來執行。
因此，event loop 讓 JS 雖然只有一條主執行緒，卻能用非同步的方式安排工作，不會因為等待 I/O 就整個程式卡死，雖然機器有 4 核、8 核，但主程式「同一時間」只能吃到其中一顆核心。

因此在不升級單核 CPU 的前提下，我這邊整理出幾種實際可以執行的解法: 

## 解法一：降低輪詢頻率（調整 interval）  


在高頻輪詢的架構裡，很多「重計算」其實是被輪詢驅動的。直接降低輪詢頻率（interval）可以讓 CPU bound 的邏輯觸發次數下降，進而讓 event loop 壓力減輕。  

以 Uptime Kuma 為例，每個監控都是一條輪詢任務：例如有 1000 個監控，每 60 秒就要發一次請求、判斷成功／失敗、更新狀態與儀表板。這些動作本身就是吃 CPU 的邏輯，如果 interval 設太短，就會在同一段時間內把一大堆「重計算」一起塞進同一條 event loop。適度拉長輪詢頻率（例如從 15 秒調成 30 秒，或把不那麼關鍵的監控改成更長間隔），可以直接減少這些 CPU-bound 邏輯被觸發的次數，讓 event loop 壓力下降、整體卡頓感也會跟著改善。




---

## 解法二：改成多節點（水平擴充 Uptime Kuma）

當單機資源有限時，將監控分散到多台節點是更穩健的做法。每個節點只負責一部分監控，狀態透過共用儲存（DB/Redis）統一，前面可加反向代理或任務分配層。

參考：我對多節點/Cluster 的思路與做法整理在這篇文章，可作為延伸閱讀：[Uptime Kuma Cluster 實作筆記](https://blog.markkulab.net/implement-uptime-kuma-cluster-vibe-coding/)

### 實作要點

- 共用儲存：資料庫/Redis 作為單一事實來源，避免節點只放記憶體狀態。
- 任務分片：用標籤、哈希或佇列將監控分配到不同節點；避免重複監控。
- 健康監測與接手：節點故障時，任務能被其他節點自動接手（Failover）。
- 可觀測性：集中化日誌、指標與告警，利於維運與問題定位。

### 效果

- 單機壓力顯著降低，整體吞吐與可用性提升。
- 故障隔離更好，節點出問題不會拖垮整體服務。

---

## 解法三：引入 Bun 作為高效能 Runtime

### Bun 是什麼？
在和同事討論 Uptime Kuma 的時候，他建議我可以試試 Bun，所以我就順勢往下研究了一下。Bun 本質上是一個主打高效能的 JavaScript Runtime，特色大致有：

- JIT / runtime 設計偏向高效能，對啟動與執行效率都有優化
- 內建打包器、測試工具、套件管理（`bun install`）等等
- 對 Node.js API 有一定程度的相容，但不是 100%（這點要特別注意）

---

## 解法四：把重計算丟給 Worker Threads

> 註：此段為我目前的研究紀錄，尚未在專案中完成實作；內容著重思路與示意，非落地方案。

我研究的做法是 **針對「重計算」本身下手**，把最吃 CPU 的那一塊抽出去，丟給 `worker_threads` 處理。

### 適合丟給 Worker Threads 的東西

- 根據監控結果重新計算各節點的 **權重與健康度**
- 執行 **複雜的規則判斷**（例如多條件 failover 策略）
- 對大量監控做 **批次分析 / 排序 / 統計**

概念上就是：主執行緒負責：

- 接收監控結果
- 排隊 / 分派任務給 worker
- 接收 worker 算完的結果，更新狀態

而真正重的邏輯，搬去 worker 檔案裡去跑。

### 程式範例

一個簡化版的程式骨架大概像這樣（示意，不是完整程式）：

```javascript
// main.js
const { Worker } = require("worker_threads");

function recalcLoadBalancing(monitors) {
  return new Promise((resolve, reject) => {
    const worker = new Worker("./recalc-worker.js", {
      workerData: { monitors },
    });

    worker.on("message", (result) => resolve(result));
    worker.on("error", reject);
    worker.on("exit", (code) => {
      if (code !== 0) reject(new Error(`Worker exited: ${code}`));
    });
  });
}
```

```javascript
// recalc-worker.js
const { parentPort, workerData } = require("worker_threads");

function heavyRecalc(monitors) {
  // 在這裡做複雜、吃 CPU 的演算法
  // 回傳新的節點權重 / 排序結果等等
  return { /* ... */ };
}

const result = heavyRecalc(workerData.monitors);
parentPort.postMessage(result);
```

這樣一來：

- 主執行緒不再被「一次算 800 個監控的負載」卡死
- 即使在老舊 CPU 上，UI 頓的感覺會明顯改善
- 要多吃幾顆核心，只要開多幾個 worker 就好（當然要控制數量）

---

## 解法五：Cluster / 多個 Node process 吃滿多核心

> 註：此段為研究方向與可行性分析，尚未實作於現有服務。

如果你的服務本身是 **多使用者、多請求的 Web API**，除了把重計算抽出去，其實也可以再用 **Cluster / 多 process** 來分散負載。

概念類似：

- 用 `cluster` 或 PM2 把同一個 Node.js 應用跑成多個 process
- 例如一台 4 核 CPU，就開 4 個 worker process
- 前面再用一層反向代理（Nginx / HAProxy / Traefik）做負載平衡

### Cluster 範例

```javascript
const cluster = require("cluster");
const os = require("os");

if (cluster.isMaster) {
  const numCPUs = os.cpus().length;
  console.log(`Master process ${process.pid} is running`);
  console.log(`Forking ${numCPUs} workers...`);

  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on("exit", (worker, code, signal) => {
    console.log(`Worker ${worker.process.pid} died, restarting...`);
    cluster.fork();
  });
} else {
  // Worker process - 執行實際的應用邏輯
  require("./app.js");
  console.log(`Worker ${process.pid} started`);
}
```

---

## 總結

| 方案 | 適用場景 | 優點 | 缺點 |
|------|----------|------|------|
| 降低輪詢頻率（interval） | 高頻輪詢導致壓力 | 減少重計算次數、降低主迴圈負載 | 反應時間變慢、可能漏短暫故障 |
| 多節點（水平擴充） | 單機資源有限、需要擴展 | 分散負載、故障隔離、易於橫向擴張 | 跨節點同步與配置複雜度提高 |
| Bun | 新腳本、獨立服務 | 執行速度快、啟動快 | 相容性還不是 100% |
| Worker Threads | CPU bound 重計算 | 不阻塞主執行緒、可利用多核心 | 需要處理資料序列化 |
| Cluster | 多請求 Web 服務 | 多 process 分散負載、容錯性高 | 狀態需共用儲存 |

如果你現在也在幫其他 Node.js 處理效能問題，又剛好卡在老機器跑不動，可以試試以上方法。
